
services:
  # MySQL : Base de données relationnelle pour stocker les données de l'application.
  mysql:
    image: mysql:8.0.22   
    container_name: mysql
    command: --default-authentication-plugin=mysql_native_password    
    restart: always   
    ports:
      - '3306:3306'
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: gestion_bibliotheque
      MYSQL_USER: myuser
      MYSQL_PASSWORD: mypassword
      JAEGER_REPORTER_LOG_SPANS: true
      JAEGER_SAMPLER_PARAM: 1
      JAEGER_SAMPLER_TYPE: const
    volumes:
      - ./mysql/db.sql:/docker-entrypoint-initdb.d/db.sql
      - ./mysql/app:/app
      - ./mysql/data:/var/lib/mysql
    healthcheck:
      test: mysqladmin ping -h 127.0.0.1 -u root --password=$$MYSQL_ROOT_PASSWORD
      start_period: 5s
      interval: 5s
      timeout: 20s
      retries: 10
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'

    # logging:
    #   driver: "json-file"  # Utiliser le driver de log par défaut

  # Redis : Système de cache pour accélérer l'application et gérer les files d'attente
  redis:
    container_name: redis
    image: redis:7.2.4    
    ports:
      - '6379:6379'
    volumes:
      - ./redis/data:/data
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'


  # Flask (WSGI) : Framework web pour exécuter l'application, avec l'intégration OpenTelemetry pour exporter des traces.
  wsgi:
    build:
      context: ./myapp
      dockerfile: Dockerfile
    image: wsgi:1.0
    container_name: wsgi
    restart: always
    volumes:
      - ./myapp:/app
    working_dir: /app
    environment:
      - MYSQL_PORT=3306
      - FLASK_ENV=production
      - APP_NAME=Bibliotheque
      - REDIS_URL=redis://redis:6379/0   
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=none
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otelcol:4318/
      - OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
      - OTEL_SERVICE_NAME=backend   
      - JAEGER_AGENT_HOST=jaeger
      - JAEGER_AGENT_PORT=6831
      - JAEGER_REPORTER_LOG_SPANS=true
      - JAEGER_SAMPLER_PARAM=1
      - JAEGER_SAMPLER_TYPE=const
    ports:
      - "5000:5000"
    expose:
      - 8080
      - 5000
    depends_on:
      - mysql
      - redis
      - otelcol
   #   - prometheus
   #  - grafana
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'


  # Nginx : Serveur HTTP inverseur pour servir l'application web et répartir la charge.
  nginx:
    build:
        context: ./nginx
        dockerfile: Dockerfile
    container_name: nginx
    # image: nginx:latest
    restart: always
    volumes: 
      - './nginx/configs/opentelemetry_module.conf:/etc/nginx/conf.d/opentelemetry_module.conf'
      - './nginx/configs/default.conf:/etc/nginx/conf.d/default.conf'
      - './nginx/www:/var/www/html'
      - './nginx/log:/var/log/nginx'
    ports:
      - '8000:80'
    depends_on:
      - wsgi
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'


  # Collecte et exporte les traces, logs et métriques vers Prometheus (pour les métriques), Loki (pour les logs) et Jaeger ou Tempo (pour les traces).
  otelcol:
    container_name: otelcol
    image: otel/opentelemetry-collector:latest   
    volumes:
      - ./otel-collector/configs/otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
      - ./otel-collector/logs/:/tmp/logs/
    ports:
      - "4317:4317"  # OTLP gRPC for traces 
      - "4318:4318" # Default endpoint for OpenTelemetry receiver.
      - "4318:4318/udp"
      - "3500:3500" # loki receiver HTTP     
      - "9464:9464" # prometheus 
      # - "55679:55679" # Default endpoint for ZPages.
      # - "14250:14250" # Default endpoint for Jaeger gRPC receiver.
      # - "14268:14268" # Default endpoint for Jaeger HTTP receiver.
      # - "9411:9411"   # Default endpoint for Zipkin receiver.     
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
    networks:
      - biblio_net
    depends_on:
      - prometheus
      - loki
      - jaeger

  # Grafana: Plateforme de visualisation des données pour observer les métriques (de Prometheus), les logs (de Loki), et les traces (de OpenTelemetry/Jaeger).
  grafana:
    image: grafana/grafana:10.2.0
    # build:
    #   context: ./grafana
    container_name: grafana  
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      # - ./grafana/grafana.ini:/etc/grafana/grafana.ini
      # - ./grafana/dashboards-provisioning/dashboard.yaml:/etc/grafana/provisioning/dashboards/main.yaml
      # - ./grafana/dashboards:/var/lib/grafana/dashboards
      - ./grafana/datasources/datasource.yml:/etc/grafana/provisioning/datasources/grafana_datasources.yml
    depends_on:
      - prometheus
      - loki
      - jaeger
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_ANALYTICS_REPORTING_ENABLED: false
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'


  # Système de surveillance pour collecter et stocker les métriques de l'infrastructure (comme l'utilisation du CPU, la RAM, etc.).
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: always
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'


  # Loki : Stocke les logs et les rend disponibles pour visualisation via Grafana.
  loki:
    image: grafana/loki:3.0.0
    container_name: loki
    command :  -config.file=/etc/loki/loki-config.yml 
    ports:
      - "3100:3100"
      - "9016"
    volumes:
      - ./loki/data:/data
      - ./loki/configs:/etc/loki/
    networks:
      - biblio_net

  
  # Promtail : Collecte des logs des fichiers locaux (par exemple /var/log) et les envoie à Loki.
  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    command: -config.file=/etc/promtail/config.yml
    ports:
      - 9080
      - 33391
    volumes:
      - ./var/log:/var/log
      - ./promtail/config.yml:/etc/promtail/config.yml
      - /var/run/docker.sock:/var/run/docker.sock # neccessary for docker logging (do not forget the plugin!!)
    networks:
      - biblio_net
    # logging:
    #   driver: loki
    #   options:
    #     loki-url: 'http://localhost:3100/api/prom/push'
  
  # Jaeger : Permet la collecte et la visualisation des traces distribuées pour déboguer et observer les flux entre les microservices.
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    volumes:
      - "./jaeger/jaeger-ui.json:/etc/jaeger/jaeger-ui.json"
    command: --query.ui-config /etc/jaeger/jaeger-ui.json
    environment:
      - METRICS_STORAGE_TYPE=prometheus
      - PROMETHEUS_SERVER_URL=http://prometheus:9090
      - PROMETHEUS_QUERY_NAMESPACE=${PROMETHEUS_QUERY_NAMESPACE:-}
      - PROMETHEUS_QUERY_DURATION_UNIT=${PROMETHEUS_QUERY_DURATION_UNIT:-}
      - PROMETHEUS_QUERY_NORMALIZE_CALLS=true
      - PROMETHEUS_QUERY_NORMALIZE_DURATION=true
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - 16686:16686  # UI Jaeger
      - 14250  # gRPC
      - 14268  # HTTP
      - 5775/udp 
      - 6831/udp 
      - 6832/udp 
      - 5778       
      - 9411 
    networks:
      - biblio_net
    # environment:
    #   


networks:
  biblio_net:
    name: biblio_net
    driver: bridge

volumes:
  grafana_data: {}
    
